# August 1st, 2017

YouTube link: [https://www.youtube.com/watch?v=kDfsGQ2dD4E](https://www.youtube.com/watch?v=kDfsGQ2dD4E)

## Purpose
To discuss various questions proposed by the OpenMined community.  Questions were posted in the YouTube Live Chat feed, as well as on our Slack channel, and on a [Github gist](https://gist.github.com/anoff/518dd6518a491789573be33c1cd723f7).

## Next Steps
- Create discussion around adapters, data transformation, marketplace, feature engineering, etc.  This topic needs to be more thought out and potentially allow for custom schemas to be created.
- We need to determine the best form of homomorphic encryption and inevitably run performance testing.
- We need to determine if mines should publicize their computational power
- The meeting time was difficult for a few members to attend.  We'll need to decide on a more inclusive timezone.

## Questions
How does `pySonar` / `Sonar` work?
> `pySonar` is a user facing library exposing the models to build.  Sonar is the blockchain OpenMined runs on top of.

Is `pySonar` only run locally on the data scientists machine?
> Yes. Just use it in a notebook or tooling of your choice and submit your model into the Open Mined network.

Is `Sonar` just a smart contract?
> Smart Contracts and abstraction layer to the underlying blockchain tech.

Is the schema for blockchain info fixed?
> No, the blockchain is schema agnostic.

How is the model serialized/deserialized (`pySonar`?)
> Just pickled model for now.

Do `pySonar` and `syft` need to be kept in sync/version controlled because models are implicitly shared between the two?
> `syft` is the library used by the data scientist to create the model. `pySonar` is only used to push the model into the ecosystem.

When we talk about gradients what exactly are they?
> They are the differential between the neural network pre-training and post-training.  In other words, it's a description of how much a neural network needs to change given a mine's data.

Who is responsible for calculating the success (gradient?) of the Mine?
> The data scientist generating the model has a validation set. The new gradients are checked against the validation set.

Can multiple Mines train at once?
> Yes, gradients are computed for multiple Mine trainings and change the model afterwards by aggregating all the gradients. Compare it to batching in traditional deep learning. Multiple Miners generate a batch.

Can the changes generated by a Mine be considered differential changes and be applied in random order?
> No, mining should occur in a somehow sequential order where you build your gradients on top of other peoples gradients. The batch analogy works here again. You can't train the model with one huge batch.

Does the Mine regularly poll the blockchain?
> Full history of training is on blockchain.

How does the Mine determine if it is able to run a network?
> If there is appropriate data on a Mine that's being requested by the network then it is able to participate in training the network.

How is data passed to `syft`?
> It's called directly from the Mine, which is in Node.  `syft` is a python task that can be called from Node.

What does the Mine do with the results from syft?
> It uploads the completed gradient back to Sonar.

Can Miners specify a minimum reward they expect for their data? e.g. mining costs need to be taken care of
> Yes, but it's not a part of the immediate feature set.

Is the first Miner on the network the one gaining the biggest reward?
> At the beginning the error goes down a lot more than near the end. However it is necessary for Miners to stick around.

Does a data scientist have an influence on mine availability?
> Miners might get incentivized to stay online and do reproducible training. Maybe improved payout for subsequent trainings with the same dataset.

Most of the descriptions of homomorphic encryption I've seen is that it's impractical because it is computationally expensive, how is it different now?
> There are various forms of homomorphic encryption available today.  Currently we support two version, but we need help in speeding this process up significantly.

What are adapters?
> Used to convert raw data into usable format by the model/`syft`. Need more discussion into separating data ingestion and feature engineering.

Is there one or two roles to Capsule? It's definitely responsible for generating PGP public/private keys with `Sonar`, but should it also be responsible for delivering decrypted results to a data scientist?
> The smart contract can contact capsule to decrypt specific values. No other part in the ecosystem can decrypt stuff.

Should adapters be a part of a "marketplace" where you can convert data from any format into the Open Mined schemas?
> Definitely.  This is a much larger discussion and will show up in the "Next Steps" section.

Would it be possible for someone to scrape a website and upload a plethora of multiple user's data in order to receive a larger bounty?
> Verified profiles might get improved bounty (chosen by the data scientist)

Are miners identifiable?
> No.

Is reputation with the Miner or the combination of Miner & Model?
> If a user gives consistently useful gradients the 'batch size' might be increased and a Miners data used longer without validating it. Basically building a system of trust.

Do mines automatically enroll for a neural net they have data for on behalf of the owner?
> Miners should be able to be able to set their mine into an auto mode that automatically mines things according to preferences set by the miner.
